{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This project is aimed at scraping and analyzing the reviews from Rotten Tomatoes website for movie \"Eternals\". \n",
    "\n",
    "The first main part of this project includes data aquisition through webscraping technique and data cleaning/wrangling process. The website of Rotten Tomatoes is javascript-rendered. Thus, the Python package Selenium is used for webscraping. \n",
    "\n",
    "The second part of this project is focusing on sentiment analysis on audiences' reviews. It is conducted through Vader sentiment algorithem provided by natural langaue toolkit package in python,NLTK. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Data aquisition + Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data aquisition- Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed python packages \n",
    "# !pip install selenium\n",
    "import selenium \n",
    "from selenium import webdriver\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import FreqDist, word_tokenize\n",
    "import re\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# (Optiona) check current working directory \n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to build Chrome webdriver to automatically browser webpages from rotten tomatoes's website and parse the web elements\n",
    "driver = webdriver.Chrome(executable_path=r'/Users/stephanie/Downloads/chromedriver')\n",
    "driver.set_page_load_timeout(30)\n",
    "driver.get(\"https://www.rottentomatoes.com/m/eternals/reviews?type=verified_audience&intcmp=rt-scorecard_audience-score-reviews\")\n",
    "\n",
    "# to create an empty list for storing the scraped data\n",
    "data = []\n",
    "\n",
    "# to scrape users and their reviews for this movie from the 1st page all the way to the 199th page and store scrapped data into the list \"data\"\n",
    "for i in range (1,200):\n",
    "    reviews = driver.find_elements_by_xpath(\"//ul[@class='audience-reviews']/li\")\n",
    "    for review in reviews:\n",
    "        user_name=review.find_element_by_xpath(\"div/div/span[@class='audience-reviews__name']\").text\n",
    "        user_review=review.find_element_by_xpath(\"div[2]/p[1]\").text\n",
    "        data.append([user_name,user_review])\n",
    "\n",
    "    try:\n",
    "        # click \"next\" button to the next page\n",
    "        driver.find_element_by_xpath(\"//nav[@class='prev-next-paging__wrapper']/button[@class='js-prev-next-paging-next btn prev-next-paging__button prev-next-paging__button-right']\").click()\n",
    "        time.sleep(10)\n",
    "\n",
    "\n",
    "    except e:\n",
    "        print(e)\n",
    "        break\n",
    "        \n",
    "# close the web driver when the work is completed   \n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning -Text processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split scraped data into 2 lists: a list of just movie review called data_review and a list of user's name called \"data_user\"\n",
    "data_review= [i[1] for i in data]\n",
    "data_user=[i[0]for i in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a funcation called \"cleanedreview\" to clean up the movie reviews which removes unneccesary characters and meaningless stopwords in English\n",
    "def cleanedreview(reviews):\n",
    "    clean_reviews=[]\n",
    "    for review in reviews:\n",
    "        print(review)\n",
    "        # convert each item in the list to string in lowercase. Remove unneccesary characters such as ?!\"\" and only keep alphanumeric characters\n",
    "        review = re.sub(\"[@#$%^&*()]\", \" \", review.lower())\n",
    "        # remove useless stopwords    \n",
    "        All_stoplist = set(stopwords.words('english'))\n",
    "        review = [word for word in review.split() if word not in All_stoplist and len(word) > 2]\n",
    "        clean_reviews.append( \" \".join(review))\n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass movie reviews into this function to obtain cleaned reviews\n",
    "clean_reviews=cleanedreview(data_review)\n",
    "# consolidate the data_user list and cleaned data_review list into a disctionary called data_cleaned with key \"User\" and value \"Review\" pairs\n",
    "data_cleaned = {'User':data_user,'Review':clean_reviews}\n",
    "# convert this disctionary into dataframe\n",
    "df = pd.DataFrame(data_cleaned)\n",
    "# save the cleaned data into a csv file \n",
    "df.to_csv('rotten_movie_review.csv')\n",
    "# display summary info of this dataframe \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 10 rows of this dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vader Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the csv file with review data into a new dataframe called \"df_1\" for further analysis\n",
    "df_1=pd.read_csv('rotten_movie_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the 1st 5 rows of this new dataframe to ensure data looks good\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a SentimentIntensityAnalyzer object\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "# The polarity_scores method of SentimentIntensityAnalyzer object returns a sentiment dictionary,which contains pos, neg, neu, and compound scores.\n",
    "# The compound score is computed by normalizing the sum of positive,negative, and neutral scores \n",
    "# and will be shown in normalized format whcih between -1(most negative) and 1 (most positive).\n",
    "# Then store these ratings into different columns in df dataframe\n",
    "df_1['compound'] = [analyzer.polarity_scores(x)['compound'] for x in df_1['Review']]\n",
    "df_1['neg'] = [analyzer.polarity_scores(x)['neg'] for x in df_1['Review']]\n",
    "df_1['neu'] = [analyzer.polarity_scores(x)['neu'] for x in df_1['Review']]\n",
    "df_1['pos'] = [analyzer.polarity_scores(x)['pos'] for x in df_1['Review']]\n",
    "# Create a new column to mark if the review is negative or positive based on resulted compound score.\n",
    "# if compound score is >=0, then mark the review as \"pos\", else \"neg\"\n",
    "df_1['Rating'] = df_1['compound'].apply(lambda x: 'pos'if x>=0 else 'neg')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display the 1st 15 rows of this dataframe \n",
    "df_1.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show the top 5 postive reviews \n",
    "df_1.sort_values('compound', ascending=False).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show the top 5 negative reviews \n",
    "df_1.sort_values('compound', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show descriptive statistics for the all numeric ratings \n",
    "df_1.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The mean compound score of the movie reviews is around 0.5 and only 25 percentile of the reviews score less than 0.27. This implies that most of the reviews are positive for this movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot the compound ratings in histagrams\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.hist(df_1['compound'], bins=20)\n",
    "plt.title('Histogram of Movie Reviews')\n",
    "plt.xlabel('Compound score')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From the above bar charts, it demonstrates again that most of the reviews fall on positive range. And significant number of reviews are highly positive. It can also be observed that there is an outstanding peak for the number of neutral reviews compared to negative reviews which show a much more flat pattern through out the negative scoring range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to group data by \"Rating\" column and show the size in bar chart\n",
    "df_1.groupby('Rating').size().plot.bar()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Again, this bar chart demonstrates that the majority of the reviews are positive.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python package for wordcloud\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create wordcloud to show words that are frequently used in the reviews\n",
    "wordcloud = WordCloud().generate(' '.join(df_1['Review']))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
